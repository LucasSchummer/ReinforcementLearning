{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e6e1d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pygame\\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import ale_py\n",
    "import torch\n",
    "import time\n",
    "\n",
    "from agents.a2c import A2C\n",
    "from envs.ale_utils import FrameStack, setup_training_dir, load_checkpoint, save_checkpoint, eval_model, generate_video, save_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ca566e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95f2f738",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_envs = 8\n",
    "n_frame_stack = 4\n",
    "n_steps = 10\n",
    "max_timesteps = 10000000\n",
    "gamma = .99\n",
    "lr = 2.5e-4\n",
    "c_actor = 1\n",
    "c_critic = .25\n",
    "c_entropy = .01\n",
    "max_grad_norm = .5\n",
    "checkpoint_frequency = 10000\n",
    "video_frequency = 10000\n",
    "eval_frequency = 5000\n",
    "n_episodes_eval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4d1927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "envs = gym.make_vec(\"ALE/Breakout-v5\", num_envs=num_envs, vectorization_mode=\"sync\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7892b025",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_training = True\n",
    "version = \"v3\"\n",
    "checkpoint = f\"training/a2c/{version}/training3/2350000.pth\"\n",
    "training_number = setup_training_dir(resume_training, \"a2c\", version)\n",
    "\n",
    "max_training_time = .1 #h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "497b105b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = A2C(input_channels=n_frame_stack, n_actions=4, \n",
    "            gamma=gamma, max_grad_norm=max_grad_norm, \n",
    "            c_actor=c_actor, c_critic=c_critic, c_entropy=c_entropy, device=device)\n",
    "framestack = FrameStack(num_envs, n_frame_stack, 84, 84, device)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "ev_states = torch.load(\"ev_states/breakout_ev_states.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc114186",
   "metadata": {},
   "outputs": [],
   "source": [
    "if resume_training:\n",
    "    training_vars = load_checkpoint(model, optimizer, checkpoint, device)\n",
    "    timestep_start, losses, avg_returns = training_vars\n",
    "else:\n",
    "    timestep_start = 0\n",
    "    losses = []\n",
    "    avg_returns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42695eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average return after 2350000 timesteps : 90.2\n",
      "Average return after 2355000 timesteps : 106.3\n",
      "Average return after 2360000 timesteps : 113.5\n",
      "Maximum training time of 0.1h exceeded. Interrupting training after 2361282 timesteps.\n"
     ]
    }
   ],
   "source": [
    "obs, infos = envs.reset()\n",
    "state = framestack.reset(obs)\n",
    "\n",
    "current_lives = infos['lives'] + 1 # Set the number of lives to play FIRE on first frame\n",
    "logits_buffer, log_probs_buffer, values_buffer = [], [], []\n",
    "rewards_buffer, next_values_buffer, dones_buffer = [], [], []\n",
    "\n",
    "start_time = time.time()\n",
    "for timestep in range(timestep_start, max_timesteps):\n",
    "\n",
    "  \n",
    "    actor_logits, value = model(state)\n",
    "    m = torch.distributions.Categorical(logits=actor_logits)\n",
    "    action = m.sample()\n",
    "    \n",
    "    log_prob = m.log_prob(action)\n",
    "\n",
    "    obs, reward, terminated, truncated, infos = envs.step(action)\n",
    "    next_state = framestack.step(obs)\n",
    "    \n",
    "    done = terminated | truncated\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _, next_value = model(next_state) \n",
    "\n",
    "    logits_buffer.append(actor_logits) # tensor (n_env, n_actions)\n",
    "    log_probs_buffer.append(log_prob) # tensor (n_env)\n",
    "    values_buffer.append(value.squeeze(-1)) # tensor (n_env)\n",
    "    rewards_buffer.append(reward) # np_array (n_env)\n",
    "    next_values_buffer.append(next_value.squeeze(-1)) # tensor (n_env) Detach from computational graph because only used for bootstraping\n",
    "    dones_buffer.append(done.astype(float)) # np_array (n_env)\n",
    "\n",
    "    state = next_state\n",
    "    \n",
    "    if (timestep + 1) % n_steps == 0:\n",
    "        update_losses = model.update(optimizer, logits_buffer, log_probs_buffer, values_buffer, rewards_buffer, next_values_buffer, dones_buffer)\n",
    "        # losses.append(update_losses)\n",
    "        logits_buffer, log_probs_buffer, values_buffer = [], [], [] # Clear buffers\n",
    "        rewards_buffer, next_values_buffer, dones_buffer = [], [], []\n",
    "\n",
    "    if (timestep + 1) % eval_frequency == 0:\n",
    "        avg_return = eval_model(model, \"ALE/Breakout-v5\", n_episodes_eval, device)\n",
    "        avg_returns.append(avg_return)\n",
    "        print(f\"Average return after {timestep + 1} timesteps : {avg_return}\")\n",
    "        save_plots([], avg_returns, f\"training/a2c/{version}/training{training_number}\", timestep+1, eval_frequency, plot_losses=False)\n",
    "    \n",
    "    if (timestep + 1) % video_frequency == 0:\n",
    "        generate_video(model, \"ALE/Breakout-v5\", f\"training/a2c/{version}/training{training_number}/{timestep+1}.mp4\", device)\n",
    "\n",
    "    if (timestep + 1) % checkpoint_frequency == 0:\n",
    "        save_checkpoint(model, optimizer, timestep, losses, avg_returns, f\"training/a2c/{version}/training{training_number}/{timestep+1}.pth\")\n",
    "\n",
    "    if time.time() - start_time > 3600 * max_training_time:\n",
    "        print(f\"Maximum training time of {max_training_time}h exceeded. Interrupting training after {timestep} timesteps.\")\n",
    "        break \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a154b224",
   "metadata": {},
   "source": [
    "After 2350000 timesteps : Out of Memory because of losses\n",
    "-> Stop saving ang logging them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fb7c35",
   "metadata": {},
   "source": [
    "Time per timestep : (with 4 envs and n_step=10)\n",
    "- Eval (+ plots) (/eval_frequency) : 4s for 10 bad ep\n",
    "- Backward (*1/n_step) : 1e-1\n",
    "- Forward (*2) : 2e-3\n",
    "- Step : 3e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c37234df",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert 1 == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f70bc95",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba64acf8",
   "metadata": {},
   "source": [
    "Run 1 episode to estimate time of different actions each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5138fce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step_times = []\n",
    "# forward_times = []\n",
    "# backward_times = []\n",
    "\n",
    "\n",
    "# tot_t_start = time.time()\n",
    "\n",
    "# done = False\n",
    "# doFire = True # Start game by using FIRE\n",
    "# ep_return = 0\n",
    "# last_frames = deque(maxlen=frame_stack)\n",
    "# logits, log_probs, values, rewards, next_values, dones = [], [], [], [], [], []\n",
    "\n",
    "# frame, info = env.reset()\n",
    "# current_lives = info['lives']\n",
    "# phi_frame = preprocess_frame(frame)\n",
    "\n",
    "# # Initially, fill the last_frames buffer with the first frame\n",
    "# for _ in range(frame_stack):\n",
    "#     last_frames.append(phi_frame)\n",
    "\n",
    "# state = get_state(last_frames, device)\n",
    "\n",
    "# while not done:\n",
    "    \n",
    "#     tic = time.time()\n",
    "#     actor_logits, value = model(state)\n",
    "#     forward_times.append(time.time() - tic)\n",
    "#     m = torch.distributions.Categorical(logits=actor_logits)\n",
    "#     action = m.sample()\n",
    "#     log_prob = m.log_prob(action)\n",
    "\n",
    "#     if doFire: # Do FIRE action if just lost a life to launch back the game\n",
    "#         action = torch.tensor([1])\n",
    "#         log_prob = m.log_prob(action)\n",
    "#         doFire = False\n",
    "\n",
    "#     tic = time.time()\n",
    "#     frame, reward, done, truncated, info = env.step(action.item())\n",
    "#     step_times.append(time.time() - tic)\n",
    "\n",
    "#     if info['lives'] > current_lives: # Do FIRE next frame if just lost a life\n",
    "#         doFire = True\n",
    "#         current_lives = info['lives']\n",
    "\n",
    "#     phi_frame = preprocess_frame(frame)\n",
    "#     last_frames.append(phi_frame) # Automatically removes the oldest frame\n",
    "#     next_state = get_state(last_frames)\n",
    "\n",
    "#     ep_return += reward\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         _, next_value = model(next_state)\n",
    "\n",
    "#     logits.append(actor_logits.squeeze(0))\n",
    "#     log_probs.append(log_prob)\n",
    "#     values.append(value)\n",
    "#     rewards.append(reward)\n",
    "#     next_values.append(next_value)\n",
    "#     dones.append(float(done))\n",
    "\n",
    "#     state = next_state\n",
    "\n",
    "#     if len(log_probs) == batch_size or done:\n",
    "        \n",
    "#         tic = time.time()\n",
    "#         update_network(optimizer, logits, log_probs, values, rewards, next_values, dones, gamma, c_actor, c_critic, c_entropy)\n",
    "#         backward_times.append(time.time() - tic)\n",
    "#         logits, log_probs, values, rewards, next_values, dones = [], [], [], [], [], [] # Clear buffers\n",
    "\n",
    "# returns.append(ep_return)\n",
    "\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     _, values = model(torch.cat(ev_states, dim=0)) # Evaluate average value on evaluation states\n",
    "# avg_values.append(values.mean().item())\n",
    "# model.train()\n",
    "\n",
    "# tot_time = time.time() - tot_t_start    \n",
    "\n",
    "# print(f\"Total episode time : {tot_time}\")\n",
    "# print(f\"Average time by forward pass : {np.mean(forward_times)}\")\n",
    "# print(f\"Average time by backward pass : {np.mean(backward_times)}\")\n",
    "# print(f\"Average time by env step : {np.mean(step_times)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50888431",
   "metadata": {},
   "source": [
    "The actions take approximately on my CPU (seconds) : \n",
    "\n",
    "- 1e-1 / optimizer step\n",
    "- 1e-3 / forward pass\n",
    "- 5e-4 / env step (emulator)  \n",
    "\n",
    "Clearly, the backward pass and optimization steps are the most time-consuming training operations, even though they are only performed every 20 steps. Using a GPU would definitely speed up the agent training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6f27a8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70ec0d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert 1 == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79c1fba",
   "metadata": {},
   "source": [
    "Colab Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9557f66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gymnasium[atari,accept-rom-license] ale-py torch torchvision imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0be5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/LucasSchummer/RL_ALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ec7201",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd RL_ALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0b4cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d8f6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # should print True\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
