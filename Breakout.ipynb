{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e6e1d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pygame\\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import ale_py\n",
    "import torch\n",
    "import time\n",
    "\n",
    "from agents.a2c import A2C\n",
    "from envs.ale_utils import FrameStack, setup_training_dir, load_checkpoint, save_checkpoint, eval_model, generate_video, save_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ca566e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f2f738",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_envs = 8\n",
    "n_frame_stack = 4\n",
    "n_steps = 10\n",
    "max_timesteps = 10000000\n",
    "gamma = .99\n",
    "lr = 2.5e-4\n",
    "c_actor = 1\n",
    "c_critic = .25\n",
    "c_entropy = .001\n",
    "max_grad_norm = .5\n",
    "checkpoint_frequency = 10000\n",
    "video_frequency = 10000\n",
    "eval_frequency = 5000\n",
    "n_episodes_eval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4d1927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "envs = gym.make_vec(\"ALE/Breakout-v5\", num_envs=num_envs, vectorization_mode=\"sync\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7892b025",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_training = True\n",
    "version = \"v3\"\n",
    "checkpoint = f\"training/a2c/{version}/training3/2850000.pth\"\n",
    "training_number = setup_training_dir(resume_training, \"a2c\", version)\n",
    "\n",
    "max_training_time = 10 #h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "497b105b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = A2C(input_channels=n_frame_stack, n_actions=4, \n",
    "            gamma=gamma, max_grad_norm=max_grad_norm, \n",
    "            c_actor=c_actor, c_critic=c_critic, c_entropy=c_entropy, device=device)\n",
    "framestack = FrameStack(num_envs, n_frame_stack, 84, 84, device)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "ev_states = torch.load(\"ev_states/breakout_ev_states.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc114186",
   "metadata": {},
   "outputs": [],
   "source": [
    "if resume_training:\n",
    "    training_vars = load_checkpoint(model, optimizer, checkpoint, device)\n",
    "    timestep_start, losses, avg_returns = training_vars\n",
    "else:\n",
    "    timestep_start = 0\n",
    "    losses = []\n",
    "    avg_returns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42695eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average return after 2850000 timesteps : 65.9\n",
      "Average return after 2855000 timesteps : 149.9\n",
      "Average return after 2860000 timesteps : 102.7\n",
      "Average return after 2865000 timesteps : 98.7\n",
      "Average return after 2870000 timesteps : 111.0\n",
      "Average return after 2875000 timesteps : 138.3\n",
      "Average return after 2880000 timesteps : 85.3\n",
      "Average return after 2885000 timesteps : 84.6\n",
      "Average return after 2890000 timesteps : 69.4\n",
      "Average return after 2895000 timesteps : 121.4\n",
      "Average return after 2900000 timesteps : 63.9\n",
      "Average return after 2905000 timesteps : 97.4\n",
      "Average return after 2910000 timesteps : 80.2\n",
      "Average return after 2915000 timesteps : 90.2\n",
      "Average return after 2920000 timesteps : 104.5\n",
      "Average return after 2925000 timesteps : 125.0\n",
      "Average return after 2930000 timesteps : 70.2\n",
      "Average return after 2935000 timesteps : 54.6\n",
      "Average return after 2940000 timesteps : 114.5\n",
      "Average return after 2945000 timesteps : 91.7\n",
      "Average return after 2950000 timesteps : 96.0\n",
      "Average return after 2955000 timesteps : 105.5\n",
      "Average return after 2960000 timesteps : 68.5\n",
      "Average return after 2965000 timesteps : 108.4\n",
      "Average return after 2970000 timesteps : 115.9\n",
      "Average return after 2975000 timesteps : 113.9\n",
      "Average return after 2980000 timesteps : 95.5\n",
      "Average return after 2985000 timesteps : 89.5\n",
      "Average return after 2990000 timesteps : 2.5\n",
      "Average return after 2995000 timesteps : 84.5\n",
      "Average return after 3000000 timesteps : 63.9\n",
      "Average return after 3005000 timesteps : 98.7\n",
      "Average return after 3010000 timesteps : 104.9\n",
      "Average return after 3015000 timesteps : 109.1\n",
      "Average return after 3020000 timesteps : 97.0\n",
      "Average return after 3025000 timesteps : 59.5\n",
      "Average return after 3030000 timesteps : 63.0\n",
      "Average return after 3035000 timesteps : 65.5\n",
      "Average return after 3040000 timesteps : 96.8\n",
      "Average return after 3045000 timesteps : 75.3\n",
      "Average return after 3050000 timesteps : 57.6\n",
      "Average return after 3055000 timesteps : 52.7\n",
      "Average return after 3060000 timesteps : 62.0\n",
      "Average return after 3065000 timesteps : 92.5\n",
      "Average return after 3070000 timesteps : 105.2\n",
      "Average return after 3075000 timesteps : 120.7\n",
      "Average return after 3080000 timesteps : 108.5\n",
      "Average return after 3085000 timesteps : 78.4\n",
      "Average return after 3090000 timesteps : 81.2\n",
      "Average return after 3095000 timesteps : 89.8\n",
      "Average return after 3100000 timesteps : 73.0\n",
      "Average return after 3105000 timesteps : 90.9\n",
      "Average return after 3110000 timesteps : 88.2\n",
      "Average return after 3115000 timesteps : 138.9\n",
      "Average return after 3120000 timesteps : 118.9\n",
      "Average return after 3125000 timesteps : 92.5\n",
      "Average return after 3130000 timesteps : 65.2\n",
      "Average return after 3135000 timesteps : 102.1\n",
      "Average return after 3140000 timesteps : 116.5\n",
      "Average return after 3145000 timesteps : 115.3\n",
      "Average return after 3150000 timesteps : 3.5\n",
      "Average return after 3155000 timesteps : 6.4\n",
      "Average return after 3160000 timesteps : 7.1\n",
      "Average return after 3165000 timesteps : 0.0\n",
      "Average return after 3170000 timesteps : 5.3\n",
      "Average return after 3175000 timesteps : 5.7\n",
      "Average return after 3180000 timesteps : 0.0\n",
      "Average return after 3185000 timesteps : 0.0\n",
      "Average return after 3190000 timesteps : 0.0\n",
      "Average return after 3195000 timesteps : 0.0\n",
      "Average return after 3200000 timesteps : 0.0\n",
      "Average return after 3205000 timesteps : 4.4\n",
      "Average return after 3210000 timesteps : 0.0\n",
      "Average return after 3215000 timesteps : 4.4\n",
      "Average return after 3220000 timesteps : 0.0\n",
      "Average return after 3225000 timesteps : 44.6\n",
      "Average return after 3230000 timesteps : 103.7\n",
      "Average return after 3235000 timesteps : 67.5\n",
      "Average return after 3240000 timesteps : 85.6\n",
      "Average return after 3245000 timesteps : 93.5\n",
      "Average return after 3250000 timesteps : 98.4\n",
      "Average return after 3255000 timesteps : 146.2\n",
      "Average return after 3260000 timesteps : 137.9\n",
      "Average return after 3265000 timesteps : 118.4\n",
      "Average return after 3270000 timesteps : 106.7\n",
      "Average return after 3275000 timesteps : 31.3\n",
      "Average return after 3280000 timesteps : 7.4\n",
      "Average return after 3285000 timesteps : 6.1\n",
      "Average return after 3290000 timesteps : 2.5\n",
      "Average return after 3295000 timesteps : 1.2\n",
      "Average return after 3300000 timesteps : 1.5\n",
      "Average return after 3305000 timesteps : 1.9\n",
      "Average return after 3310000 timesteps : 1.6\n",
      "Average return after 3315000 timesteps : 2.2\n",
      "Average return after 3320000 timesteps : 42.2\n",
      "Average return after 3325000 timesteps : 40.4\n",
      "Average return after 3330000 timesteps : 128.7\n",
      "Average return after 3335000 timesteps : 100.7\n",
      "Average return after 3340000 timesteps : 185.0\n",
      "Average return after 3345000 timesteps : 78.6\n",
      "Average return after 3350000 timesteps : 106.8\n",
      "Average return after 3355000 timesteps : 112.6\n",
      "Average return after 3360000 timesteps : 103.4\n",
      "Average return after 3365000 timesteps : 93.3\n",
      "Average return after 3370000 timesteps : 146.9\n",
      "Average return after 3375000 timesteps : 149.2\n",
      "Average return after 3380000 timesteps : 126.3\n",
      "Average return after 3385000 timesteps : 154.5\n",
      "Average return after 3390000 timesteps : 104.2\n",
      "Average return after 3395000 timesteps : 145.4\n",
      "Average return after 3400000 timesteps : 149.9\n",
      "Average return after 3405000 timesteps : 76.5\n",
      "Average return after 3410000 timesteps : 28.8\n",
      "Average return after 3415000 timesteps : 216.9\n",
      "Average return after 3420000 timesteps : 38.2\n",
      "Average return after 3425000 timesteps : 170.9\n",
      "Average return after 3430000 timesteps : 71.9\n",
      "Average return after 3435000 timesteps : 156.1\n",
      "Average return after 3440000 timesteps : 119.9\n",
      "Average return after 3445000 timesteps : 111.0\n",
      "Average return after 3450000 timesteps : 178.8\n",
      "Average return after 3455000 timesteps : 134.6\n",
      "Average return after 3460000 timesteps : 116.5\n",
      "Average return after 3465000 timesteps : 108.6\n",
      "Average return after 3470000 timesteps : 96.8\n",
      "Average return after 3475000 timesteps : 87.1\n",
      "Average return after 3480000 timesteps : 102.9\n",
      "Average return after 3485000 timesteps : 80.1\n",
      "Average return after 3490000 timesteps : 80.6\n",
      "Average return after 3495000 timesteps : 102.7\n",
      "Average return after 3500000 timesteps : 68.0\n",
      "Average return after 3505000 timesteps : 54.0\n",
      "Average return after 3510000 timesteps : 79.4\n",
      "Average return after 3515000 timesteps : 139.5\n",
      "Average return after 3520000 timesteps : 110.3\n",
      "Average return after 3525000 timesteps : 91.6\n",
      "Average return after 3530000 timesteps : 128.9\n",
      "Average return after 3535000 timesteps : 82.5\n",
      "Average return after 3540000 timesteps : 84.2\n",
      "Average return after 3545000 timesteps : 97.0\n",
      "Average return after 3550000 timesteps : 59.8\n",
      "Average return after 3555000 timesteps : 54.7\n",
      "Average return after 3560000 timesteps : 29.9\n",
      "Average return after 3565000 timesteps : 104.7\n",
      "Average return after 3570000 timesteps : 99.1\n",
      "Average return after 3575000 timesteps : 56.6\n",
      "Average return after 3580000 timesteps : 78.2\n",
      "Average return after 3585000 timesteps : 87.3\n",
      "Average return after 3590000 timesteps : 110.4\n",
      "Average return after 3595000 timesteps : 80.8\n",
      "Average return after 3600000 timesteps : 132.2\n",
      "Average return after 3605000 timesteps : 82.7\n",
      "Average return after 3610000 timesteps : 49.0\n",
      "Average return after 3615000 timesteps : 105.0\n",
      "Average return after 3620000 timesteps : 105.5\n",
      "Average return after 3625000 timesteps : 61.7\n",
      "Average return after 3630000 timesteps : 88.8\n",
      "Average return after 3635000 timesteps : 98.9\n",
      "Average return after 3640000 timesteps : 84.3\n",
      "Average return after 3645000 timesteps : 166.3\n",
      "Average return after 3650000 timesteps : 80.7\n",
      "Average return after 3655000 timesteps : 76.3\n",
      "Average return after 3660000 timesteps : 99.0\n",
      "Average return after 3665000 timesteps : 105.0\n",
      "Average return after 3670000 timesteps : 91.3\n",
      "Average return after 3675000 timesteps : 86.0\n",
      "Average return after 3680000 timesteps : 147.3\n",
      "Average return after 3685000 timesteps : 141.7\n",
      "Average return after 3690000 timesteps : 100.2\n",
      "Average return after 3695000 timesteps : 92.0\n",
      "Average return after 3700000 timesteps : 32.2\n",
      "Average return after 3705000 timesteps : 116.3\n",
      "Average return after 3710000 timesteps : 145.2\n",
      "Average return after 3715000 timesteps : 28.9\n",
      "Average return after 3720000 timesteps : 155.6\n",
      "Average return after 3725000 timesteps : 120.3\n",
      "Average return after 3730000 timesteps : 128.0\n",
      "Average return after 3735000 timesteps : 176.7\n",
      "Average return after 3740000 timesteps : 115.4\n",
      "Average return after 3745000 timesteps : 134.8\n",
      "Average return after 3750000 timesteps : 109.3\n",
      "Average return after 3755000 timesteps : 80.5\n",
      "Average return after 3760000 timesteps : 108.8\n",
      "Average return after 3765000 timesteps : 59.5\n",
      "Average return after 3770000 timesteps : 121.4\n",
      "Average return after 3775000 timesteps : 107.6\n",
      "Average return after 3780000 timesteps : 102.1\n",
      "Average return after 3785000 timesteps : 124.0\n",
      "Average return after 3790000 timesteps : 28.9\n",
      "Average return after 3795000 timesteps : 99.2\n",
      "Average return after 3800000 timesteps : 80.2\n",
      "Average return after 3805000 timesteps : 114.2\n",
      "Average return after 3810000 timesteps : 59.6\n",
      "Average return after 3815000 timesteps : 66.7\n",
      "Average return after 3820000 timesteps : 103.6\n",
      "Average return after 3825000 timesteps : 158.5\n",
      "Average return after 3830000 timesteps : 1.9\n",
      "Average return after 3835000 timesteps : 1.2\n",
      "Average return after 3840000 timesteps : 2.0\n",
      "Average return after 3845000 timesteps : 2.1\n",
      "Average return after 3850000 timesteps : 2.1\n",
      "Average return after 3855000 timesteps : 1.3\n",
      "Average return after 3860000 timesteps : 1.8\n",
      "Average return after 3865000 timesteps : 2.1\n",
      "Average return after 3870000 timesteps : 2.0\n",
      "Average return after 3875000 timesteps : 2.1\n",
      "Average return after 3880000 timesteps : 2.1\n",
      "Average return after 3885000 timesteps : 2.0\n",
      "Average return after 3890000 timesteps : 1.3\n",
      "Average return after 3895000 timesteps : 2.2\n",
      "Average return after 3900000 timesteps : 2.2\n",
      "Average return after 3905000 timesteps : 2.4\n",
      "Average return after 3910000 timesteps : 2.0\n",
      "Average return after 3915000 timesteps : 34.4\n",
      "Average return after 3920000 timesteps : 3.0\n",
      "Average return after 3925000 timesteps : 29.3\n",
      "Average return after 3930000 timesteps : 41.2\n",
      "Average return after 3935000 timesteps : 62.3\n",
      "Average return after 3940000 timesteps : 101.8\n",
      "Average return after 3945000 timesteps : 78.3\n",
      "Average return after 3950000 timesteps : 48.5\n",
      "Average return after 3955000 timesteps : 72.7\n",
      "Average return after 3960000 timesteps : 104.1\n",
      "Average return after 3965000 timesteps : 82.0\n",
      "Average return after 3970000 timesteps : 67.8\n",
      "Average return after 3975000 timesteps : 104.1\n",
      "Average return after 3980000 timesteps : 105.9\n",
      "Average return after 3985000 timesteps : 91.4\n",
      "Average return after 3990000 timesteps : 1.5\n",
      "Average return after 3995000 timesteps : 78.7\n",
      "Average return after 4000000 timesteps : 76.7\n",
      "Average return after 4005000 timesteps : 81.5\n",
      "Average return after 4010000 timesteps : 108.8\n",
      "Average return after 4015000 timesteps : 30.5\n",
      "Average return after 4020000 timesteps : 68.2\n",
      "Average return after 4025000 timesteps : 63.3\n",
      "Average return after 4030000 timesteps : 78.9\n",
      "Average return after 4035000 timesteps : 74.7\n",
      "Average return after 4040000 timesteps : 63.2\n",
      "Average return after 4045000 timesteps : 69.0\n",
      "Average return after 4050000 timesteps : 81.9\n",
      "Average return after 4055000 timesteps : 59.1\n",
      "Average return after 4060000 timesteps : 63.8\n",
      "Average return after 4065000 timesteps : 186.9\n",
      "Average return after 4070000 timesteps : 118.2\n",
      "Average return after 4075000 timesteps : 29.7\n",
      "Average return after 4080000 timesteps : 46.1\n",
      "Average return after 4085000 timesteps : 108.2\n",
      "Average return after 4090000 timesteps : 121.1\n",
      "Average return after 4095000 timesteps : 80.6\n",
      "Average return after 4100000 timesteps : 110.0\n",
      "Average return after 4105000 timesteps : 47.1\n",
      "Average return after 4110000 timesteps : 102.5\n",
      "Average return after 4115000 timesteps : 124.1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m state \u001b[38;5;241m=\u001b[39m next_state\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (timestep \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m n_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 36\u001b[0m     update_losses \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogits_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_probs_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrewards_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_values_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdones_buffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;66;03m# losses.append(update_losses)\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     logits_buffer, log_probs_buffer, values_buffer \u001b[38;5;241m=\u001b[39m [], [], [] \u001b[38;5;66;03m# Clear buffers\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lucas\\Documents\\Coursera\\RL Specialization\\RL_applications\\ALE\\agents\\a2c.py:70\u001b[0m, in \u001b[0;36mA2C.update\u001b[1;34m(self, optimizer, logits_buffer, log_probs_buffer, values_buffer, rewards_buffer, next_values_buffer, dones_buffer)\u001b[0m\n\u001b[0;32m     68\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     69\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_grad_norm)\n\u001b[1;32m---> 70\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (loss\u001b[38;5;241m.\u001b[39mitem(), actor_loss\u001b[38;5;241m.\u001b[39mitem(), critic_loss\u001b[38;5;241m.\u001b[39mitem(), entropy\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\optim\\optimizer.py:516\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    511\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    512\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    513\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    514\u001b[0m             )\n\u001b[1;32m--> 516\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    519\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\optim\\optimizer.py:81\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     79\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     80\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 81\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     83\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\optim\\adam.py:247\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    235\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    237\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    238\u001b[0m         group,\n\u001b[0;32m    239\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    244\u001b[0m         state_steps,\n\u001b[0;32m    245\u001b[0m     )\n\u001b[1;32m--> 247\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdecoupled_weight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\optim\\optimizer.py:149\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\optim\\adam.py:949\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    946\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    947\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 949\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    950\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    951\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    954\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\optim\\adam.py:533\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[0m\n\u001b[0;32m    531\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    532\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 533\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    535\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[0;32m    537\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "obs, infos = envs.reset()\n",
    "state = framestack.reset(obs)\n",
    "\n",
    "current_lives = infos['lives'] + 1 # Set the number of lives to play FIRE on first frame\n",
    "logits_buffer, log_probs_buffer, values_buffer = [], [], []\n",
    "rewards_buffer, next_values_buffer, dones_buffer = [], [], []\n",
    "\n",
    "start_time = time.time()\n",
    "for timestep in range(timestep_start, max_timesteps):\n",
    "\n",
    "  \n",
    "    actor_logits, value = model(state)\n",
    "    m = torch.distributions.Categorical(logits=actor_logits)\n",
    "    action = m.sample()\n",
    "    \n",
    "    log_prob = m.log_prob(action)\n",
    "\n",
    "    obs, reward, terminated, truncated, infos = envs.step(action)\n",
    "    next_state = framestack.step(obs)\n",
    "    \n",
    "    done = terminated | truncated\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _, next_value = model(next_state) \n",
    "\n",
    "    logits_buffer.append(actor_logits) # tensor (n_env, n_actions)\n",
    "    log_probs_buffer.append(log_prob) # tensor (n_env)\n",
    "    values_buffer.append(value.squeeze(-1)) # tensor (n_env)\n",
    "    rewards_buffer.append(reward) # np_array (n_env)\n",
    "    next_values_buffer.append(next_value.squeeze(-1)) # tensor (n_env) Detach from computational graph because only used for bootstraping\n",
    "    dones_buffer.append(done.astype(float)) # np_array (n_env)\n",
    "\n",
    "    state = next_state\n",
    "    \n",
    "    if (timestep + 1) % n_steps == 0:\n",
    "        update_losses = model.update(optimizer, logits_buffer, log_probs_buffer, values_buffer, rewards_buffer, next_values_buffer, dones_buffer)\n",
    "        # losses.append(update_losses)\n",
    "        logits_buffer, log_probs_buffer, values_buffer = [], [], [] # Clear buffers\n",
    "        rewards_buffer, next_values_buffer, dones_buffer = [], [], []\n",
    "\n",
    "    if (timestep + 1) % eval_frequency == 0:\n",
    "        avg_return = eval_model(model, \"ALE/Breakout-v5\", n_episodes_eval, device)\n",
    "        avg_returns.append(avg_return)\n",
    "        print(f\"Average return after {timestep + 1} timesteps : {avg_return}\")\n",
    "        save_plots([], avg_returns, f\"training/a2c/{version}/training{training_number}\", timestep+1, eval_frequency, plot_losses=False)\n",
    "    \n",
    "    if (timestep + 1) % video_frequency == 0:\n",
    "        generate_video(model, \"ALE/Breakout-v5\", f\"training/a2c/{version}/training{training_number}/{timestep+1}.mp4\", device)\n",
    "\n",
    "    if (timestep + 1) % checkpoint_frequency == 0:\n",
    "        save_checkpoint(model, optimizer, timestep, losses, avg_returns, f\"training/a2c/{version}/training{training_number}/{timestep+1}.pth\")\n",
    "\n",
    "    if time.time() - start_time > 3600 * max_training_time:\n",
    "        print(f\"Maximum training time of {max_training_time}h exceeded. Interrupting training after {timestep} timesteps.\")\n",
    "        break \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a154b224",
   "metadata": {},
   "source": [
    "After 2350000 timesteps : Out of Memory because of losses\n",
    "-> Stop saving ang logging them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fb7c35",
   "metadata": {},
   "source": [
    "Time per timestep : (with 4 envs and n_step=10)\n",
    "- Eval (+ plots) (/eval_frequency) : 4s for 10 bad ep\n",
    "- Backward (*1/n_step) : 1e-1\n",
    "- Forward (*2) : 2e-3\n",
    "- Step : 3e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37234df",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert 1 == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f70bc95",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba64acf8",
   "metadata": {},
   "source": [
    "Run 1 episode to estimate time of different actions each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5138fce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step_times = []\n",
    "# forward_times = []\n",
    "# backward_times = []\n",
    "\n",
    "\n",
    "# tot_t_start = time.time()\n",
    "\n",
    "# done = False\n",
    "# doFire = True # Start game by using FIRE\n",
    "# ep_return = 0\n",
    "# last_frames = deque(maxlen=frame_stack)\n",
    "# logits, log_probs, values, rewards, next_values, dones = [], [], [], [], [], []\n",
    "\n",
    "# frame, info = env.reset()\n",
    "# current_lives = info['lives']\n",
    "# phi_frame = preprocess_frame(frame)\n",
    "\n",
    "# # Initially, fill the last_frames buffer with the first frame\n",
    "# for _ in range(frame_stack):\n",
    "#     last_frames.append(phi_frame)\n",
    "\n",
    "# state = get_state(last_frames, device)\n",
    "\n",
    "# while not done:\n",
    "    \n",
    "#     tic = time.time()\n",
    "#     actor_logits, value = model(state)\n",
    "#     forward_times.append(time.time() - tic)\n",
    "#     m = torch.distributions.Categorical(logits=actor_logits)\n",
    "#     action = m.sample()\n",
    "#     log_prob = m.log_prob(action)\n",
    "\n",
    "#     if doFire: # Do FIRE action if just lost a life to launch back the game\n",
    "#         action = torch.tensor([1])\n",
    "#         log_prob = m.log_prob(action)\n",
    "#         doFire = False\n",
    "\n",
    "#     tic = time.time()\n",
    "#     frame, reward, done, truncated, info = env.step(action.item())\n",
    "#     step_times.append(time.time() - tic)\n",
    "\n",
    "#     if info['lives'] > current_lives: # Do FIRE next frame if just lost a life\n",
    "#         doFire = True\n",
    "#         current_lives = info['lives']\n",
    "\n",
    "#     phi_frame = preprocess_frame(frame)\n",
    "#     last_frames.append(phi_frame) # Automatically removes the oldest frame\n",
    "#     next_state = get_state(last_frames)\n",
    "\n",
    "#     ep_return += reward\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         _, next_value = model(next_state)\n",
    "\n",
    "#     logits.append(actor_logits.squeeze(0))\n",
    "#     log_probs.append(log_prob)\n",
    "#     values.append(value)\n",
    "#     rewards.append(reward)\n",
    "#     next_values.append(next_value)\n",
    "#     dones.append(float(done))\n",
    "\n",
    "#     state = next_state\n",
    "\n",
    "#     if len(log_probs) == batch_size or done:\n",
    "        \n",
    "#         tic = time.time()\n",
    "#         update_network(optimizer, logits, log_probs, values, rewards, next_values, dones, gamma, c_actor, c_critic, c_entropy)\n",
    "#         backward_times.append(time.time() - tic)\n",
    "#         logits, log_probs, values, rewards, next_values, dones = [], [], [], [], [], [] # Clear buffers\n",
    "\n",
    "# returns.append(ep_return)\n",
    "\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     _, values = model(torch.cat(ev_states, dim=0)) # Evaluate average value on evaluation states\n",
    "# avg_values.append(values.mean().item())\n",
    "# model.train()\n",
    "\n",
    "# tot_time = time.time() - tot_t_start    \n",
    "\n",
    "# print(f\"Total episode time : {tot_time}\")\n",
    "# print(f\"Average time by forward pass : {np.mean(forward_times)}\")\n",
    "# print(f\"Average time by backward pass : {np.mean(backward_times)}\")\n",
    "# print(f\"Average time by env step : {np.mean(step_times)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50888431",
   "metadata": {},
   "source": [
    "The actions take approximately on my CPU (seconds) : \n",
    "\n",
    "- 1e-1 / optimizer step\n",
    "- 1e-3 / forward pass\n",
    "- 5e-4 / env step (emulator)  \n",
    "\n",
    "Clearly, the backward pass and optimization steps are the most time-consuming training operations, even though they are only performed every 20 steps. Using a GPU would definitely speed up the agent training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6f27a8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70ec0d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert 1 == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79c1fba",
   "metadata": {},
   "source": [
    "Colab Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9557f66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gymnasium[atari,accept-rom-license] ale-py torch torchvision imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0be5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/LucasSchummer/RL_ALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ec7201",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd RL_ALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0b4cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d8f6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # should print True\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
